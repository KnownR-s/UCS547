{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "755bbfae",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f523d4ef",
   "metadata": {},
   "source": [
    "\n",
    "- `!` → Executes shell commands from a notebook cell (e.g., `!ls`, `!nvcc --version`).\n",
    "- `%` → Line magic command (operates on a single line, e.g., `%time`, `%matplotlib inline`).\n",
    "- `%%` → Cell magic command (applies to the entire cell, e.g., `%%time`, `%%writefile file.cu`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d5d792",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe3b822",
   "metadata": {},
   "source": [
    "\n",
    "Common `nvidia-smi` commands:\n",
    "\n",
    "- `nvidia-smi`\n",
    "- `nvidia-smi -L`\n",
    "- `nvidia-smi -q`\n",
    "- `nvidia-smi -q -d MEMORY`\n",
    "- `nvidia-smi -q -d UTILIZATION`\n",
    "- `nvidia-smi --help`\n",
    "- `nvidia-smi topo -m`\n",
    "- `nvidia-smi pmon -i 0`\n",
    "- `nvidia-smi dmon`\n",
    "- `nvidia-smi --gpu-reset -i 0`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e157258",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56194938",
   "metadata": {},
   "source": [
    "\n",
    "Common CUDA Errors:\n",
    "\n",
    "1. Zero Output:\n",
    "   - Kernel not launched properly\n",
    "   - Missing cudaMemcpy\n",
    "   - Synchronization issue (use cudaDeviceSynchronize())\n",
    "\n",
    "2. Incorrect Indexing:\n",
    "   - Wrong global thread ID calculation\n",
    "   - Out-of-bounds memory access\n",
    "   - Incorrect grid/block configuration\n",
    "\n",
    "3. PTX Errors:\n",
    "   - Unsupported architecture (use correct `-arch=sm_xx`)\n",
    "   - CUDA toolkit mismatch\n",
    "   - Syntax errors in kernel code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f77a33",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fe7993",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%writefile hello_gpu.cu\n",
    "#include <stdio.h>\n",
    "\n",
    "// Device Code (GPU Kernel)\n",
    "__global__ void helloKernel() {\n",
    "    int global_thread_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    printf(\"Hello from GPU thread %d\\n\", global_thread_id);\n",
    "}\n",
    "\n",
    "// Host Code (CPU)\n",
    "int main() {\n",
    "    helloKernel<<<1, 8>>>();   // 1 block, 8 threads\n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d0067",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2006dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%writefile memory_demo.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Device Code\n",
    "__global__ void printKernel(int *d_array) {\n",
    "    int idx = threadIdx.x;\n",
    "    printf(\"GPU Thread %d: %d\\n\", idx, d_array[idx]);\n",
    "}\n",
    "\n",
    "// Host Code\n",
    "int main() {\n",
    "    int h_array[5] = {10, 20, 30, 40, 50};\n",
    "    int *d_array;\n",
    "\n",
    "    cudaMalloc((void**)&d_array, 5 * sizeof(int));\n",
    "    cudaMemcpy(d_array, h_array, 5 * sizeof(int), cudaMemcpyHostToDevice);\n",
    "\n",
    "    printKernel<<<1, 5>>>(d_array);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    cudaMemcpy(h_array, d_array, 5 * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    printf(\"Back on CPU:\\n\");\n",
    "    for(int i = 0; i < 5; i++) {\n",
    "        printf(\"%d \", h_array[i]);\n",
    "    }\n",
    "\n",
    "    cudaFree(d_array);\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e775e551",
   "metadata": {},
   "source": [
    "## 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95227713",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# List timing\n",
    "start = time.time()\n",
    "lst = [i for i in range(1000000)]\n",
    "end = time.time()\n",
    "print(\"List time:\", end - start)\n",
    "\n",
    "# Tuple timing\n",
    "start = time.time()\n",
    "tpl = tuple(i for i in range(1000000))\n",
    "end = time.time()\n",
    "print(\"Tuple time:\", end - start)\n",
    "\n",
    "# NumPy timing\n",
    "start = time.time()\n",
    "arr = np.arange(1000000)\n",
    "end = time.time()\n",
    "print(\"NumPy time:\", end - start)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
